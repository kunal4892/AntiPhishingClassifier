{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti Phishing Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# Metrics for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classification Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset and X_train Y_train and X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_url = 'datasets/urlset.csv'\n",
    "# data = pd.read_csv(dataset_url)\n",
    "# data = shuffle(data).reset_index(drop=True)\n",
    "# #data.shape\n",
    "# labels = data.iloc[:, lambda df: [-1]]\n",
    "# data = data.loc[:,lambda df:['domain', 'ranking']]\n",
    "# #labels.shape\n",
    "# #X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.33, random_state=42)\n",
    "# #X_train.shape\n",
    "# #X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Features set from Featureset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureset = 'featureset/cleaned_data.csv'\n",
    "# data = pd.read_csv(featureset)\n",
    "# data = shuffle(data).reset_index(drop=True)\n",
    "# labels = data.iloc[:, lambda df: [-1]]\n",
    "# data = data.iloc[:,:-2]\n",
    "# data.shape\n",
    "# sscaler = StandardScaler()\n",
    "# #data = sscaler.fit_transform(data)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset_with_whois = 'featureset/cleaned_data_withwhois.csv'\n",
    "data = pd.read_csv(featureset_with_whois)\n",
    "sscaler = StandardScaler()\n",
    "#data = sscaler.fit_transform(data)\n",
    "labels = data.iloc[:, lambda df: [-1]]\n",
    "data = data.iloc[:,1:-2]\n",
    "\n",
    "train_data = data.iloc[0:4000,:]\n",
    "labels_train = labels.iloc[0:4000,:]\n",
    "\n",
    "test_data = data.iloc[4000:,:]\n",
    "labels_test = labels.iloc[4000:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features is used to create features for the classification:\n",
    "'''\n",
    "1. Domain\n",
    "2. URL_length\n",
    "3. URL_slashes_count\n",
    "4. URL_dots_count\n",
    "5. URL_hostname_len\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(data_frame):\n",
    "#     url = data_frame['domain']\n",
    "#     len_url = []\n",
    "#     for u in url:\n",
    "#         len_url.append(len(u))\n",
    "\n",
    "#     data_frame['URL_length'] = pd.Series(len_url)\n",
    " \n",
    "    count_slashes = []\n",
    "    for u in url:\n",
    "        count_slashes.append(u.count('//') )\n",
    "    data_frame['URL_slashes_count'] = pd.Series(count_slashes)\n",
    "    \n",
    "#     count_dots = []\n",
    "#     for u in url:\n",
    "#         count_dots.append(u.count('.') )\n",
    "#     data_frame['URL_dots_count'] = pd.Series(count_dots)\n",
    "\n",
    "#     len_hostname = []\n",
    "#     start = '://'\n",
    "#     end = '/'\n",
    "\n",
    "#     for u in url:\n",
    "#         temp = u[u.find(start)+2*len(start) + 2: u.rfind(end)]\n",
    "#         temp = temp.replace('/','.')\n",
    "#         temp = temp.replace('-','.')\n",
    "#         len_hostname.append(len(temp.split('.')))\n",
    "\n",
    "#     data_frame['URL_hostname_len'] = pd.Series(len_hostname)\n",
    "#     data_frame = data_frame.iloc[:,1:]\n",
    "    return data_frame\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classify classifies the data in different using all the different  classifiers.\n",
    "\n",
    "'''\n",
    "1. Log-Regression\n",
    "2. K-Nearest Neighbors - @params knn neighbors\n",
    "3. Decision Tree - @params maximum depth\n",
    "4. Random Forest - @params maximum depth, criterion, max_features, num_of_estimators\n",
    "5. AdaBoost\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_clf_after_CrossVal(train_x, train_y, classifier_parameter_map):\n",
    "    scoring_evals = {'AUC': 'roc_auc',\n",
    "                     'Accuracy': make_scorer(accuracy_score),\n",
    "                     'f1': make_scorer(f1_score)\n",
    "                    }\n",
    "    clf_list=[]\n",
    "    for key in classifier_parameter_map:\n",
    "        clf = GridSearchCV(classifier_parameter_map[key][0],\n",
    "                     classifier_parameter_map[key][1],\n",
    "                     #iid=False,\n",
    "                     scoring = 'accuracy',\n",
    "                     #refit = 'Accuracy',\n",
    "                     cv=10, # no of validations\n",
    "                     n_jobs = -1 # use full concurrency\n",
    "                    )\n",
    "        \n",
    "        result = clf.fit(train_x, train_y)\n",
    "        #print(clf.cv_results_)\n",
    "        print(result.best_estimator_)\n",
    "        print('score: ', result.best_score_)\n",
    "        clf_list.append(result.best_estimator_)\n",
    "    return clf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " def classify(train_x, train_y):\n",
    "           \n",
    "    logreg_parameters = {\n",
    "     'penalty': ['l1','l2']\n",
    "    }\n",
    "    \n",
    "    knn_parameters = {\n",
    "       'n_neighbors': np.arange(2,100,1),\n",
    "       'weights': ['distance'],\n",
    "       'metric': ['minkowski']\n",
    "    }\n",
    "    dt_parameters = {\n",
    "        'min_samples_split' : range(2,50,2),\n",
    "        #'max_depth': range(1,50,2)\n",
    "    }\n",
    "    \n",
    "    rf_parameters = {\n",
    "    #'bootstrap': [True],\n",
    "    'max_depth': range(1,20,1),\n",
    "    'n_estimators': range(2,100,1)\n",
    "    }\n",
    "    \n",
    "    classifier_parameter_map = {\"Log-Regression\": (LogisticRegression(), logreg_parameters),\n",
    "                          \"K-Nearest Neighbors\": (KNeighborsClassifier(), knn_parameters),\n",
    "                          \"Decision Tree\": (DecisionTreeClassifier(), dt_parameters),\n",
    "                          \"Random Forest\": (RandomForestClassifier(), rf_parameters)}\n",
    "                                            #\"AdaBoost\"}\n",
    "        \n",
    "    clf_list = get_best_clf_after_CrossVal(train_x, train_y, classifier_parameter_map)\n",
    "    print(len(clf_list))\n",
    "    return clf_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kumar4892/projects/fml/py3venv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "score:  0.85125\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=96, p=2,\n",
      "                     weights='distance')\n",
      "score:  0.89175\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=14,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "score:  0.88925\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=34,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "score:  0.91175\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf_list = classify(train_data, np.ravel(labels_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['Log-Regression', 'K-Nearest Neighbors', 'Decision Tree', 'Random Forest']\n",
    "for clfname, clf in zip(classifiers, clf_list):\n",
    "    filename = str(clfname) + (str('.sav'))\n",
    "    pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.871\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Spam       0.86      0.88      0.87       496\n",
      "  Legitimate       0.88      0.86      0.87       504\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.87      0.87      0.87      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "Accuracy\n",
      "0.897\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Spam       0.89      0.91      0.90       496\n",
      "  Legitimate       0.91      0.89      0.90       504\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "Accuracy\n",
      "0.885\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Spam       0.88      0.89      0.88       496\n",
      "  Legitimate       0.89      0.88      0.89       504\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.88      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "Accuracy\n",
      "0.912\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Spam       0.93      0.90      0.91       496\n",
      "  Legitimate       0.90      0.93      0.91       504\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clfname, clf in zip(classifiers, clf_list):\n",
    "    labels_pred = clf.predict(test_data)\n",
    "    print(clfname)\n",
    "    print('Accuracy: ', accuracy_score(labels_test, labels_pred))\n",
    "    print('Classification report')\n",
    "    print(classification_report(labels_test, labels_pred, target_names=['Spam','Legitimate']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
